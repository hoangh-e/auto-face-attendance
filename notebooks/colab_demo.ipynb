{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üéØ AI Attendance System - Enhanced Colab Demo\n",
        "\n",
        "**SCRFD Detection + ArcFace Recognition + SQLite Database**\n",
        "\n",
        "Pipeline V1: `hoangh-e/auto-face-attendance/tree/pipeline-v1.0/`\n",
        "\n",
        "---\n",
        "\n",
        "## üåü Features Overview\n",
        "\n",
        "‚úÖ **Quick Setup**: One-cell installation with progress tracking  \n",
        "‚úÖ **Employee Management**: Batch registration with ZIP file upload  \n",
        "‚úÖ **Advanced Video Processing**: Multi-format support with real-time metrics  \n",
        "‚úÖ **Performance Dashboard**: Live charts and comprehensive analytics  \n",
        "‚úÖ **Export Functionality**: JSON, CSV, Excel with attendance reports  \n",
        "\n",
        "**üöÄ Ready for immediate testing and evaluation!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Cell 1: ‚ö° Quick Setup & Installation\n",
        "\n",
        "**Automated installation with GPU detection and environment optimization**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AI Attendance System - Enhanced Colab Demo\n",
        "# Quick Setup & Installation\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import platform\n",
        "\n",
        "print(\"üéØ AI ATTENDANCE SYSTEM - ENHANCED COLAB DEMO\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Environment Detection\n",
        "print(\"üîç ENVIRONMENT DETECTION:\")\n",
        "print(f\"‚îú‚îÄ Platform: {platform.system()} {platform.release()}\")\n",
        "print(f\"‚îú‚îÄ Python: {sys.version.split()[0]}\")\n",
        "print(f\"‚îú‚îÄ Working Directory: {os.getcwd()}\")\n",
        "\n",
        "# GPU Detection\n",
        "try:\n",
        "    import torch\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    if gpu_available:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"üöÄ GPU: ‚úÖ {gpu_name} ({gpu_memory:.1f}GB)\")\n",
        "    else:\n",
        "        print(f\"üíª GPU: ‚ùå CPU mode (slower but functional)\")\n",
        "except ImportError:\n",
        "    print(f\"üì¶ PyTorch: Installing...\")\n",
        "    gpu_available = False\n",
        "\n",
        "# Install packages with progress tracking\n",
        "print(f\"\\nüì¶ INSTALLING PACKAGES:\")\n",
        "\n",
        "packages = [\n",
        "    'torch>=1.9.0',\n",
        "    'torchvision>=0.10.0', \n",
        "    'insightface>=0.7.3',\n",
        "    'opencv-python>=4.5.0',\n",
        "    'scikit-learn>=1.0.0',\n",
        "    'matplotlib>=3.5.0',\n",
        "    'pandas>=1.3.0',\n",
        "    'tqdm>=4.62.0',\n",
        "    'pillow>=8.3.0',\n",
        "    'numpy>=1.21.0'\n",
        "]\n",
        "\n",
        "for i, package in enumerate(packages, 1):\n",
        "    try:\n",
        "        print(f\"‚îú‚îÄ [{i}/{len(packages)}] Installing {package.split('>=')[0]}...\")\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, '-m', 'pip', 'install', package, '--quiet'],\n",
        "            capture_output=True, text=True, timeout=120\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(f\"    ‚úÖ Installed successfully\")\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Already installed or skipped\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"    ‚ö†Ô∏è Installation timeout, continuing...\")\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Error: {e}\")\n",
        "\n",
        "# Create directories\n",
        "work_dir = Path('/content') if 'google.colab' in sys.modules else Path.cwd()\n",
        "data_dir = work_dir / 'attendance_data'\n",
        "employees_dir = data_dir / 'employees'\n",
        "videos_dir = data_dir / 'videos'\n",
        "exports_dir = data_dir / 'exports'\n",
        "\n",
        "for directory in [data_dir, employees_dir, videos_dir, exports_dir]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nüìÅ DIRECTORY STRUCTURE:\")\n",
        "print(f\"‚îú‚îÄ Data: {data_dir}\")\n",
        "print(f\"‚îú‚îÄ Employees: {employees_dir}\")\n",
        "print(f\"‚îú‚îÄ Videos: {videos_dir}\")\n",
        "print(f\"‚îî‚îÄ Exports: {exports_dir}\")\n",
        "\n",
        "print(f\"\\nüéâ SETUP COMPLETED!\")\n",
        "print(f\"Ready for employee registration and video processing!\")\n",
        "print(\"=\" * 55)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Cell 2: ü§ñ AI Models & Database Initialization\n",
        "\n",
        "**Initialize SCRFD + ArcFace models with SQLite database**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AI Models & Database Initialization\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import sqlite3\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Optional\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# AI and ML imports\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"ü§ñ INITIALIZING AI MODELS & DATABASE\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ColabAISystem:\n",
        "    \"\"\"Enhanced AI system for Colab demo\"\"\"\n",
        "    \n",
        "    def __init__(self, model_pack='buffalo_l'):\n",
        "        self.model_pack = model_pack\n",
        "        self.app = None\n",
        "        self.performance_stats = {\n",
        "            'total_inferences': 0,\n",
        "            'avg_latency_ms': 0.0,\n",
        "            'total_time': 0.0,\n",
        "            'gpu_available': False\n",
        "        }\n",
        "        self._init_models()\n",
        "    \n",
        "    def _init_models(self):\n",
        "        \"\"\"Initialize InsightFace models\"\"\"\n",
        "        try:\n",
        "            import torch\n",
        "            if torch.cuda.is_available():\n",
        "                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "                self.performance_stats['gpu_available'] = True\n",
        "                print(f\"üöÄ GPU Mode: {torch.cuda.get_device_name(0)}\")\n",
        "            else:\n",
        "                providers = ['CPUExecutionProvider']\n",
        "                print(\"üíª CPU Mode: Slower but functional\")\n",
        "            \n",
        "            print(f\"üì¶ Loading {self.model_pack} model pack...\")\n",
        "            self.app = FaceAnalysis(name=self.model_pack, providers=providers)\n",
        "            \n",
        "            # Prepare with optimal settings\n",
        "            ctx_id = 0 if torch.cuda.is_available() else -1\n",
        "            self.app.prepare(ctx_id=ctx_id, det_size=(640, 640), det_thresh=0.5)\n",
        "            \n",
        "            print(f\"‚úÖ {self.model_pack} loaded successfully!\")\n",
        "            \n",
        "            # Performance test\n",
        "            self._test_performance()\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model loading failed: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def _test_performance(self):\n",
        "        \"\"\"Test model performance\"\"\"\n",
        "        print(\"üß™ Testing model performance...\")\n",
        "        \n",
        "        # Create test image\n",
        "        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Run multiple inferences\n",
        "        times = []\n",
        "        for _ in range(5):\n",
        "            start = time.time()\n",
        "            self.app.get(test_image)\n",
        "            times.append((time.time() - start) * 1000)\n",
        "        \n",
        "        avg_time = np.mean(times)\n",
        "        print(f\"  ‚îú‚îÄ Average inference time: {avg_time:.1f}ms\")\n",
        "        \n",
        "        if avg_time < 100:\n",
        "            print(f\"  ‚îî‚îÄ Performance: üåü EXCELLENT (real-time capable)\")\n",
        "        elif avg_time < 300:\n",
        "            print(f\"  ‚îî‚îÄ Performance: üëç GOOD\")\n",
        "        else:\n",
        "            print(f\"  ‚îî‚îÄ Performance: ‚ö†Ô∏è SLOW (consider lighter model)\")\n",
        "    \n",
        "    def detect_and_recognize(self, image):\n",
        "        \"\"\"Process image and return face data\"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            faces = self.app.get(image)\n",
        "            \n",
        "            results = []\n",
        "            for face in faces:\n",
        "                result = {\n",
        "                    'bbox': face.bbox,\n",
        "                    'det_score': float(face.det_score),\n",
        "                    'landmarks': getattr(face, 'kps', None),\n",
        "                    'embedding': face.embedding,\n",
        "                    'age': getattr(face, 'age', None),\n",
        "                    'gender': getattr(face, 'gender', None)\n",
        "                }\n",
        "                results.append(result)\n",
        "            \n",
        "            # Update performance stats\n",
        "            processing_time = (time.time() - start_time) * 1000\n",
        "            self.performance_stats['total_inferences'] += 1\n",
        "            self.performance_stats['total_time'] += processing_time\n",
        "            self.performance_stats['avg_latency_ms'] = (\n",
        "                self.performance_stats['total_time'] / \n",
        "                self.performance_stats['total_inferences']\n",
        "            )\n",
        "            \n",
        "            return results\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Processing error: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def batch_process(self, images):\n",
        "        \"\"\"Process multiple images efficiently\"\"\"\n",
        "        results = []\n",
        "        for img in tqdm(images, desc=\"Processing images\"):\n",
        "            result = self.detect_and_recognize(img)\n",
        "            results.append(result)\n",
        "        return results\n",
        "\n",
        "class ColabDatabase:\n",
        "    \"\"\"Enhanced SQLite database for Colab demo\"\"\"\n",
        "    \n",
        "    def __init__(self, db_path=\"colab_attendance.db\"):\n",
        "        self.db_path = data_dir / db_path\n",
        "        self.conn = sqlite3.connect(str(self.db_path), check_same_thread=False)\n",
        "        self.conn.row_factory = sqlite3.Row\n",
        "        self._create_tables()\n",
        "        logger.info(f\"Database initialized: {self.db_path}\")\n",
        "    \n",
        "    def _create_tables(self):\n",
        "        \"\"\"Create database tables\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        \n",
        "        # Employees table\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS employees (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            employee_code TEXT UNIQUE NOT NULL,\n",
        "            name TEXT NOT NULL,\n",
        "            email TEXT UNIQUE NOT NULL,\n",
        "            department TEXT,\n",
        "            position TEXT,\n",
        "            face_embeddings TEXT,\n",
        "            face_count INTEGER DEFAULT 0,\n",
        "            avg_quality REAL DEFAULT 0.0,\n",
        "            is_active BOOLEAN DEFAULT 1,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Attendance logs\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS attendance_logs (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            employee_id INTEGER,\n",
        "            event_type TEXT NOT NULL,\n",
        "            timestamp TIMESTAMP NOT NULL,\n",
        "            confidence REAL NOT NULL,\n",
        "            image_data TEXT,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "            FOREIGN KEY (employee_id) REFERENCES employees (id)\n",
        "        )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Processing stats\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS processing_stats (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "            total_frames INTEGER,\n",
        "            faces_detected INTEGER,\n",
        "            employees_recognized INTEGER,\n",
        "            avg_processing_time REAL,\n",
        "            session_id TEXT\n",
        "        )\n",
        "        \"\"\")\n",
        "        \n",
        "        self.conn.commit()\n",
        "    \n",
        "    def register_employee(self, employee_data, face_embeddings):\n",
        "        \"\"\"Register employee with face embeddings\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        \n",
        "        try:\n",
        "            # Calculate average embedding\n",
        "            if face_embeddings:\n",
        "                avg_embedding = np.mean(face_embeddings, axis=0)\n",
        "                avg_quality = np.mean([np.linalg.norm(emb) for emb in face_embeddings])\n",
        "            else:\n",
        "                return None\n",
        "            \n",
        "            cursor.execute(\"\"\"\n",
        "            INSERT INTO employees \n",
        "            (employee_code, name, email, department, position, face_embeddings, \n",
        "             face_count, avg_quality)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\", (\n",
        "                employee_data['employee_code'],\n",
        "                employee_data['name'], \n",
        "                employee_data['email'],\n",
        "                employee_data.get('department', ''),\n",
        "                employee_data.get('position', ''),\n",
        "                json.dumps(avg_embedding.tolist()),\n",
        "                len(face_embeddings),\n",
        "                avg_quality\n",
        "            ))\n",
        "            \n",
        "            employee_id = cursor.lastrowid\n",
        "            self.conn.commit()\n",
        "            \n",
        "            logger.info(f\"Employee registered: {employee_data['name']} (ID: {employee_id})\")\n",
        "            return employee_id\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.conn.rollback()\n",
        "            logger.error(f\"Registration error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def find_employee_by_embedding(self, query_embedding, threshold=0.65):\n",
        "        \"\"\"Find employee by face embedding\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        \n",
        "        cursor.execute(\"\"\"\n",
        "        SELECT id, employee_code, name, email, face_embeddings\n",
        "        FROM employees WHERE is_active = 1 AND face_embeddings IS NOT NULL\n",
        "        \"\"\")\n",
        "        \n",
        "        best_match = None\n",
        "        best_similarity = 0.0\n",
        "        \n",
        "        for row in cursor.fetchall():\n",
        "            try:\n",
        "                stored_embedding = np.array(json.loads(row['face_embeddings']))\n",
        "                similarity = cosine_similarity(\n",
        "                    query_embedding.reshape(1, -1),\n",
        "                    stored_embedding.reshape(1, -1)\n",
        "                )[0][0]\n",
        "                \n",
        "                if similarity > best_similarity and similarity > threshold:\n",
        "                    best_similarity = similarity\n",
        "                    best_match = {\n",
        "                        'id': row['id'],\n",
        "                        'employee_code': row['employee_code'],\n",
        "                        'name': row['name'],\n",
        "                        'email': row['email'],\n",
        "                        'similarity': similarity\n",
        "                    }\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        return best_match\n",
        "    \n",
        "    def record_attendance(self, employee_id, event_type, confidence, image_data=None):\n",
        "        \"\"\"Record attendance event\"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        \n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO attendance_logs (employee_id, event_type, timestamp, confidence, image_data)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\", (employee_id, event_type, timestamp, confidence, image_data))\n",
        "        \n",
        "        self.conn.commit()\n",
        "        return cursor.lastrowid\n",
        "    \n",
        "    def get_statistics(self):\n",
        "        \"\"\"Get database statistics\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        \n",
        "        stats = {}\n",
        "        \n",
        "        cursor.execute(\"SELECT COUNT(*) FROM employees WHERE is_active = 1\")\n",
        "        stats['total_employees'] = cursor.fetchone()[0]\n",
        "        \n",
        "        cursor.execute(\"SELECT COUNT(*) FROM attendance_logs\")\n",
        "        stats['total_logs'] = cursor.fetchone()[0]\n",
        "        \n",
        "        cursor.execute(\"\"\"\n",
        "        SELECT COUNT(*) FROM attendance_logs \n",
        "        WHERE DATE(timestamp) = DATE('now')\n",
        "        \"\"\")\n",
        "        stats['today_logs'] = cursor.fetchone()[0]\n",
        "        \n",
        "        return stats\n",
        "\n",
        "# Initialize systems\n",
        "print(\"üîÑ Initializing AI system...\")\n",
        "ai_system = ColabAISystem()\n",
        "\n",
        "print(\"\\nüîÑ Initializing database...\")\n",
        "db = ColabDatabase()\n",
        "\n",
        "print(f\"\\nüìä INITIALIZATION COMPLETED!\")\n",
        "print(f\"‚îú‚îÄ Model: {ai_system.model_pack}\")\n",
        "print(f\"‚îú‚îÄ GPU Available: {ai_system.performance_stats['gpu_available']}\")\n",
        "print(f\"‚îî‚îÄ Database: {db.db_path}\")\n",
        "\n",
        "# Show current statistics\n",
        "stats = db.get_statistics()\n",
        "print(f\"\\nüìà Database Statistics:\")\n",
        "print(f\"‚îú‚îÄ Employees: {stats['total_employees']}\")\n",
        "print(f\"‚îú‚îÄ Total Logs: {stats['total_logs']}\")\n",
        "print(f\"‚îî‚îÄ Today's Logs: {stats['today_logs']}\")\n",
        "\n",
        "print(\"=\" * 45)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Cell 3: üë• Employee Management System\n",
        "\n",
        "**Batch employee registration with photo upload and quality validation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Employee Management System\n",
        "\n",
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "print(\"üë• EMPLOYEE MANAGEMENT SYSTEM\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "class EmployeeManager:\n",
        "    \"\"\"Enhanced employee management for Colab\"\"\"\n",
        "    \n",
        "    def __init__(self, ai_system, database):\n",
        "        self.ai_system = ai_system\n",
        "        self.db = database\n",
        "        self.registered_employees = []\n",
        "    \n",
        "    def upload_employee_photos(self):\n",
        "        \"\"\"Upload employee photos via file picker\"\"\"\n",
        "        print(\"üì§ Employee Photo Upload\")\n",
        "        print(\"Supported formats: ZIP archives, individual images\")\n",
        "        print(\"Folder structure: employee_name/photo1.jpg, photo2.jpg, ...\")\n",
        "        \n",
        "        uploaded = files.upload()\n",
        "        \n",
        "        for filename, content in uploaded.items():\n",
        "            print(f\"\\nüìÅ Processing: {filename}\")\n",
        "            \n",
        "            if filename.endswith('.zip'):\n",
        "                self._process_zip_file(filename, content)\n",
        "            elif filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                self._process_single_image(filename, content)\n",
        "            else:\n",
        "                print(f\"  ‚ö†Ô∏è Unsupported format: {filename}\")\n",
        "    \n",
        "    def _process_zip_file(self, filename, content):\n",
        "        \"\"\"Process ZIP file with employee folders\"\"\"\n",
        "        zip_path = employees_dir / filename\n",
        "        \n",
        "        # Save ZIP file\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            f.write(content)\n",
        "        \n",
        "        # Extract ZIP\n",
        "        extract_dir = employees_dir / 'extracted'\n",
        "        extract_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "            \n",
        "            print(f\"  ‚úÖ Extracted to: {extract_dir}\")\n",
        "            \n",
        "            # Process extracted folders\n",
        "            self._scan_employee_folders(extract_dir)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå ZIP extraction error: {e}\")\n",
        "        finally:\n",
        "            # Cleanup\n",
        "            if zip_path.exists():\n",
        "                zip_path.unlink()\n",
        "    \n",
        "    def _process_single_image(self, filename, content):\n",
        "        \"\"\"Process single image file\"\"\"\n",
        "        # Extract employee name from filename\n",
        "        employee_name = filename.split('.')[0].replace('_', ' ').title()\n",
        "        \n",
        "        # Save image\n",
        "        img_path = employees_dir / filename\n",
        "        with open(img_path, 'wb') as f:\n",
        "            f.write(content)\n",
        "        \n",
        "        # Process image\n",
        "        try:\n",
        "            image = cv2.imread(str(img_path))\n",
        "            if image is not None:\n",
        "                self._register_single_employee(employee_name, [image])\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error processing {filename}: {e}\")\n",
        "    \n",
        "    def _scan_employee_folders(self, base_dir):\n",
        "        \"\"\"Scan and process employee folders\"\"\"\n",
        "        employee_folders = [f for f in base_dir.iterdir() \n",
        "                           if f.is_dir() and not f.name.startswith('.')]\n",
        "        \n",
        "        if not employee_folders:\n",
        "            print(f\"  ‚ö†Ô∏è No employee folders found\")\n",
        "            return\n",
        "        \n",
        "        print(f\"  üìÅ Found {len(employee_folders)} employee folders\")\n",
        "        \n",
        "        for folder in tqdm(employee_folders, desc=\"Processing employees\"):\n",
        "            employee_name = folder.name.replace('_', ' ').title()\n",
        "            \n",
        "            # Find image files\n",
        "            image_files = []\n",
        "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
        "                image_files.extend(folder.glob(ext))\n",
        "            \n",
        "            if not image_files:\n",
        "                print(f\"  ‚ö†Ô∏è No images in {folder.name}\")\n",
        "                continue\n",
        "            \n",
        "            # Load images\n",
        "            images = []\n",
        "            for img_file in image_files:\n",
        "                try:\n",
        "                    img = cv2.imread(str(img_file))\n",
        "                    if img is not None:\n",
        "                        images.append(img)\n",
        "                except:\n",
        "                    continue\n",
        "            \n",
        "            if images:\n",
        "                self._register_single_employee(employee_name, images)\n",
        "    \n",
        "    def _register_single_employee(self, employee_name, images):\n",
        "        \"\"\"Register single employee with images\"\"\"\n",
        "        print(f\"\\\\nüë§ Processing: {employee_name}\")\n",
        "        \n",
        "        # Extract face embeddings\n",
        "        face_embeddings = []\n",
        "        quality_scores = []\n",
        "        processed_count = 0\n",
        "        \n",
        "        for i, image in enumerate(images):\n",
        "            try:\n",
        "                faces = self.ai_system.detect_and_recognize(image)\n",
        "                \n",
        "                if len(faces) == 1:  # Exactly one face\n",
        "                    face_data = faces[0]\n",
        "                    \n",
        "                    if face_data['det_score'] > 0.7:  # Good quality\n",
        "                        face_embeddings.append(face_data['embedding'])\n",
        "                        quality_scores.append(face_data['det_score'])\n",
        "                        processed_count += 1\n",
        "                        print(f\"  ‚úÖ Image {i+1}: confidence {face_data['det_score']:.3f}\")\n",
        "                    else:\n",
        "                        print(f\"  ‚ö†Ô∏è Image {i+1}: low quality ({face_data['det_score']:.3f})\")\n",
        "                elif len(faces) == 0:\n",
        "                    print(f\"  ‚ùå Image {i+1}: no face detected\")\n",
        "                else:\n",
        "                    print(f\"  ‚ö†Ô∏è Image {i+1}: multiple faces ({len(faces)})\") \n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Image {i+1}: error - {e}\")\n",
        "        \n",
        "        # Register employee if sufficient faces\n",
        "        if len(face_embeddings) >= 1:\n",
        "            # Create employee data\n",
        "            employee_code = employee_name.upper().replace(' ', '_')\n",
        "            employee_data = {\n",
        "                'employee_code': employee_code,\n",
        "                'name': employee_name,\n",
        "                'email': f\"{employee_code.lower()}@company.com\",\n",
        "                'department': 'Demo Department',\n",
        "                'position': 'Employee'\n",
        "            }\n",
        "            \n",
        "            # Register in database\n",
        "            employee_id = self.db.register_employee(employee_data, face_embeddings)\n",
        "            \n",
        "            if employee_id:\n",
        "                avg_quality = np.mean(quality_scores)\n",
        "                self.registered_employees.append({\n",
        "                    'id': employee_id,\n",
        "                    'name': employee_name,\n",
        "                    'face_count': len(face_embeddings),\n",
        "                    'avg_quality': avg_quality\n",
        "                })\n",
        "                \n",
        "                print(f\"  üéâ Registered: {len(face_embeddings)} faces, avg quality: {avg_quality:.3f}\")\n",
        "            else:\n",
        "                print(f\"  ‚ùå Database registration failed\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå Insufficient quality faces (need at least 1)\")\n",
        "    \n",
        "    def manual_employee_entry(self):\n",
        "        \"\"\"Manual employee entry with form\"\"\"\n",
        "        print(\"‚úèÔ∏è Manual Employee Entry\")\n",
        "        \n",
        "        # Create form widgets\n",
        "        name_widget = widgets.Text(description='Name:', placeholder='John Doe')\n",
        "        email_widget = widgets.Text(description='Email:', placeholder='john.doe@company.com')\n",
        "        dept_widget = widgets.Text(description='Department:', placeholder='Engineering')\n",
        "        position_widget = widgets.Text(description='Position:', placeholder='Developer')\n",
        "        \n",
        "        submit_button = widgets.Button(description='Register Employee')\n",
        "        output = widgets.Output()\n",
        "        \n",
        "        def on_submit(b):\n",
        "            with output:\n",
        "                clear_output()\n",
        "                \n",
        "                if not name_widget.value:\n",
        "                    print(\"‚ùå Name is required\")\n",
        "                    return\n",
        "                \n",
        "                employee_data = {\n",
        "                    'employee_code': name_widget.value.upper().replace(' ', '_'),\n",
        "                    'name': name_widget.value,\n",
        "                    'email': email_widget.value or f\"{name_widget.value.lower().replace(' ', '.')}@company.com\",\n",
        "                    'department': dept_widget.value or 'General',\n",
        "                    'position': position_widget.value or 'Employee'\n",
        "                }\n",
        "                \n",
        "                # Register without face embeddings (manual entry)\n",
        "                employee_id = self.db.register_employee(employee_data, [])\n",
        "                \n",
        "                if employee_id:\n",
        "                    print(f\"‚úÖ Employee registered: {employee_data['name']} (ID: {employee_id})\")\n",
        "                    print(\"‚ö†Ô∏è Note: No face embeddings - photos needed for recognition\")\n",
        "                else:\n",
        "                    print(\"‚ùå Registration failed\")\n",
        "        \n",
        "        submit_button.on_click(on_submit)\n",
        "        \n",
        "        # Display form\n",
        "        display(widgets.VBox([\n",
        "            name_widget, email_widget, dept_widget, position_widget,\n",
        "            submit_button, output\n",
        "        ]))\n",
        "    \n",
        "    def show_registered_employees(self):\n",
        "        \"\"\"Display registered employees table\"\"\"\n",
        "        if not self.registered_employees:\n",
        "            print(\"üìù No employees registered yet\")\n",
        "            return\n",
        "        \n",
        "        print(f\"üìã REGISTERED EMPLOYEES ({len(self.registered_employees)})\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(self.registered_employees)\n",
        "        df.index = df.index + 1  # Start from 1\n",
        "        \n",
        "        # Display table\n",
        "        display(HTML(df.to_html()))\n",
        "        \n",
        "        # Show summary statistics\n",
        "        total_faces = df['face_count'].sum()\n",
        "        avg_quality = df['avg_quality'].mean()\n",
        "        \n",
        "        print(f\"\\\\nüìä Summary:\")\n",
        "        print(f\"‚îú‚îÄ Total Employees: {len(self.registered_employees)}\")\n",
        "        print(f\"‚îú‚îÄ Total Face Images: {total_faces}\")\n",
        "        print(f\"‚îî‚îÄ Average Quality: {avg_quality:.3f}\")\n",
        "    \n",
        "    def export_employee_data(self):\n",
        "        \"\"\"Export employee data to various formats\"\"\"\n",
        "        if not self.registered_employees:\n",
        "            print(\"‚ùå No data to export\")\n",
        "            return\n",
        "        \n",
        "        print(\"üì§ Exporting employee data...\")\n",
        "        \n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(self.registered_employees)\n",
        "        \n",
        "        # Export to CSV\n",
        "        csv_path = exports_dir / 'employees.csv'\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        \n",
        "        # Export to Excel\n",
        "        excel_path = exports_dir / 'employees.xlsx'\n",
        "        df.to_excel(excel_path, index=False)\n",
        "        \n",
        "        # Export to JSON\n",
        "        json_path = exports_dir / 'employees.json'\n",
        "        df.to_json(json_path, orient='records', indent=2)\n",
        "        \n",
        "        print(f\"‚úÖ Exported to:\")\n",
        "        print(f\"‚îú‚îÄ CSV: {csv_path}\")\n",
        "        print(f\"‚îú‚îÄ Excel: {excel_path}\")\n",
        "        print(f\"‚îî‚îÄ JSON: {json_path}\")\n",
        "        \n",
        "        # Download files (Colab specific)\n",
        "        try:\n",
        "            files.download(str(csv_path))\n",
        "            files.download(str(excel_path))\n",
        "            files.download(str(json_path))\n",
        "            print(\"üì• Files downloaded to your computer\")\n",
        "        except:\n",
        "            print(\"üí° Files saved to exports/ directory\")\n",
        "\n",
        "# Initialize employee manager\n",
        "employee_manager = EmployeeManager(ai_system, db)\n",
        "\n",
        "print(\"üéØ Employee Management Options:\")\n",
        "print(\"1. Upload photos (ZIP or individual files)\")\n",
        "print(\"2. Manual entry (without photos)\")\n",
        "print(\"3. View registered employees\")\n",
        "print(\"4. Export employee data\")\n",
        "print(\"\\\\nRun the appropriate methods below:\")\n",
        "print(\"=\" * 35)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {\n",
        "    \"id\": \"header_title\"\n",
        "   },\n",
        "   \"source\": [\n",
        "    \"# üéØ AI Attendance System - Enhanced Colab Demo\\n\",\n",
        "    \"\\n\",\n",
        "    \"**Pipeline V1: SCRFD Detection + ArcFace Recognition + SQLite Database**\\n\",\n",
        "    \"\\n\",\n",
        "    \"Repository: `hoangh-e/auto-face-attendance/tree/pipeline-v1.0/`\\n\",\n",
        "    \"\\n\",\n",
        "    \"---\\n\",\n",
        "    \"\\n\",\n",
        "    \"## üìã Features Overview\\n\",\n",
        "    \"\\n\",\n",
        "    \"‚úÖ **Quick Setup**: One-cell installation with progress tracking  \\n\",\n",
        "    \"‚úÖ **Employee Management**: Batch registration with folder upload  \\n\",\n",
        "    \"‚úÖ **Advanced Video Processing**: Multi-format support with real-time metrics  \\n\",\n",
        "    \"‚úÖ **Performance Dashboard**: Live charts and statistics  \\n\",\n",
        "    \"‚úÖ **Export Functionality**: Multiple format support (JSON, CSV, Excel)  \\n\",\n",
        "    \"‚úÖ **Error Recovery**: Comprehensive error handling with user guidance  \\n\",\n",
        "    \"\\n\",\n",
        "    \"---\"\n",
        "   ]\n",
        "  }\n",
        " ]\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
